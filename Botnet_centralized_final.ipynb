{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(fileName):\n",
    "    \n",
    "    loaded_data = np.loadtxt(filename, delimiter = ',')\n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(Xy):\n",
    "    \n",
    "    #separate data and labels\n",
    "    data = np.delete(Xy, 11, 1)\n",
    "    labels = Xy[:,11].reshape(-1,1).astype(np.int8)\n",
    "    \n",
    "    #compute mean\n",
    "    mean = np.average(data, axis = 0)\n",
    "    \n",
    "    #compute standard deviation\n",
    "    standard_deviation = np.std(data, axis = 0)\n",
    "    \n",
    "    \n",
    "    #FORMULA USED TO NORMALIZE DATA: (X-mean) / standard deviation\n",
    "    \n",
    "    normalized_data = (data - mean)/standard_deviation\n",
    "    Xy_normalized = np.concatenate((normalized_data, labels), axis = 1)\n",
    "    \n",
    "    return Xy_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Xy, iterations, learning_rate):\n",
    "    \n",
    "    #separate data and labels\n",
    "    data = np.delete(Xy, 11, 1)\n",
    "    y = Xy[:,11]\n",
    "    num_rows = len(data)\n",
    "    \n",
    "    #set initial random weight and bias values\n",
    "    weight = np.random.rand(data.shape[1])\n",
    "    bias = np.random.randint(0,100)/100\n",
    "\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        y_pred = predict(weight, bias, data)\n",
    "        \n",
    "        #COMPUTE THE LOSS FUNCTION\n",
    "        loss = -np.mean((y*np.log(y_pred + epsilon)+((1-y)*np.log(1-y_pred + epsilon))))  # epsilon is a very small value added to avoid calculation problems\n",
    "        \n",
    "        #COMPUTE WEIGHT DERIVATIVE\n",
    "        weight_der =np.dot(data.T, (y_pred-y))/num_rows\n",
    "        \n",
    "        #COMPUTE BIAS DERIVATIVE\n",
    "        bias_der = np.mean((y_pred-y))\n",
    "        \n",
    "        #UPDATE WEIGHT AND BIAS VALUES\n",
    "        weight = weight - learning_rate*weight_der\n",
    "        bias = bias - learning_rate*bias_der\n",
    "        \n",
    "        acc = accuracy(weight, bias, Xy)\n",
    "        print(\"EPOCH\",i,\" ---->  LOSS: \",loss,\" ACCURACY: \",acc)\n",
    "\n",
    "        \n",
    "    return weight,bias\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(w, b, Xy):\n",
    "    \n",
    "    y = Xy[:, 11]\n",
    "    data = np.delete(Xy, 11, 1)\n",
    "    \n",
    "    \n",
    "    #get the predicted values in order to be able to compare them with the given ones\n",
    "    y_pred = predict(w,b,data)\n",
    "    #if the prediction is > 0.5, set y_pred to 1, otherwise set it to 0\n",
    "    y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "    #get the number of predicted labels matching the exact given value\n",
    "    matching = np.equal(y_pred,y)\n",
    "    #accuracy is given by the % of matching predictions over the total samples\n",
    "    acc = matching.mean()*100\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w,b,X):\n",
    "    \n",
    "    y_pred = sigmoid(np.matmul(w, X.T) + b)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    y = 1/(1+np.exp(-x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****** EXECUTION ********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "\n",
    "filename = \"../alumno/Downloads/botnet_tot_syn_l.csv\"\n",
    "epochs = 10\n",
    "learning_r = 1.5\n",
    "\n",
    "epsilon = 0.000000000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- PROVIDED EXECUTION CODE ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0  ---->  LOSS:  1.3675626410922301  ACCURACY:  62.4452\n",
      "EPOCH 1  ---->  LOSS:  0.7508346401734097  ACCURACY:  75.8562\n",
      "EPOCH 2  ---->  LOSS:  0.47946609523787526  ACCURACY:  85.2479\n",
      "EPOCH 3  ---->  LOSS:  0.36076558042049817  ACCURACY:  89.20439999999999\n",
      "EPOCH 4  ---->  LOSS:  0.3032118002104034  ACCURACY:  90.7397\n",
      "EPOCH 5  ---->  LOSS:  0.27108370351017186  ACCURACY:  91.5951\n",
      "EPOCH 6  ---->  LOSS:  0.25080338701140775  ACCURACY:  92.1775\n",
      "EPOCH 7  ---->  LOSS:  0.23682582096944002  ACCURACY:  92.5012\n",
      "EPOCH 8  ---->  LOSS:  0.22657811816764872  ACCURACY:  92.7507\n",
      "EPOCH 9  ---->  LOSS:  0.2187201274512405  ACCURACY:  92.9412\n",
      "acc:  92.9412\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data = readFile(filename)\n",
    "\n",
    "# standardize\n",
    "data = normalize(data)\n",
    "\n",
    "w, b = train(data, epochs, learning_r)\n",
    "acc = accuracy(w, b, data)\n",
    "\n",
    "print(\"acc: \", acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
